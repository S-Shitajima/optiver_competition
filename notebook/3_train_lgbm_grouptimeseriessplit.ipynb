{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from itertools import combinations\n",
    "import pathlib\n",
    "from typing import Any, Dict, List\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.evaluate.time_series import (GroupTimeSeriesSplit, plot_splits)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import polars as pl\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "gc.enable()\n",
    "pd.set_option('display.max_columns', 200)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.010200</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237975</th>\n",
       "      <td>195</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>2440722.89</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>28280361.74</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>32257.04</td>\n",
       "      <td>1.000434</td>\n",
       "      <td>319862.40</td>\n",
       "      <td>1.000328</td>\n",
       "      <td>2.310276</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237976</th>\n",
       "      <td>196</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>349510.47</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>9187699.11</td>\n",
       "      <td>1.000129</td>\n",
       "      <td>1.000386</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>205108.40</td>\n",
       "      <td>1.000900</td>\n",
       "      <td>93393.07</td>\n",
       "      <td>1.000819</td>\n",
       "      <td>-8.220077</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237977</th>\n",
       "      <td>197</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>12725436.10</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>16790.66</td>\n",
       "      <td>0.995883</td>\n",
       "      <td>180038.32</td>\n",
       "      <td>0.995797</td>\n",
       "      <td>1.169443</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237978</th>\n",
       "      <td>198</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>1000898.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>94773271.05</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>125631.72</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>669893.00</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>-1.540184</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237979</th>\n",
       "      <td>199</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>1884285.71</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>24073677.32</td>\n",
       "      <td>1.000859</td>\n",
       "      <td>1.001494</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>250081.44</td>\n",
       "      <td>1.002447</td>\n",
       "      <td>300167.56</td>\n",
       "      <td>1.002274</td>\n",
       "      <td>-6.530285</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5237980 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0               0        0                  0      3180602.69   \n",
       "1               1        0                  0       166603.91   \n",
       "2               2        0                  0       302879.87   \n",
       "3               3        0                  0     11917682.27   \n",
       "4               4        0                  0       447549.96   \n",
       "...           ...      ...                ...             ...   \n",
       "5237975       195      480                540      2440722.89   \n",
       "5237976       196      480                540       349510.47   \n",
       "5237977       197      480                540            0.00   \n",
       "5237978       198      480                540      1000898.84   \n",
       "5237979       199      480                540      1884285.71   \n",
       "\n",
       "         imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                              1         0.999812   13380276.64        NaN   \n",
       "1                             -1         0.999896    1642214.25        NaN   \n",
       "2                             -1         0.999561    1819368.03        NaN   \n",
       "3                             -1         1.000171   18389745.62        NaN   \n",
       "4                             -1         0.999532   17860614.95        NaN   \n",
       "...                          ...              ...           ...        ...   \n",
       "5237975                       -1         1.000317   28280361.74   0.999734   \n",
       "5237976                       -1         1.000643    9187699.11   1.000129   \n",
       "5237977                        0         0.995789   12725436.10   0.995789   \n",
       "5237978                        1         0.999210   94773271.05   0.999210   \n",
       "5237979                       -1         1.002129   24073677.32   1.000859   \n",
       "\n",
       "         near_price  bid_price   bid_size  ask_price   ask_size       wap  \\\n",
       "0               NaN   0.999812   60651.50   1.000026    8493.03  1.000000   \n",
       "1               NaN   0.999896    3233.04   1.000660   20605.09  1.000000   \n",
       "2               NaN   0.999403   37956.00   1.000298   18995.00  1.000000   \n",
       "3               NaN   0.999999    2324.90   1.000214  479032.40  1.000000   \n",
       "4               NaN   0.999394   16485.54   1.000016     434.10  1.000000   \n",
       "...             ...        ...        ...        ...        ...       ...   \n",
       "5237975    0.999734   1.000317   32257.04   1.000434  319862.40  1.000328   \n",
       "5237976    1.000386   1.000643  205108.40   1.000900   93393.07  1.000819   \n",
       "5237977    0.995789   0.995789   16790.66   0.995883  180038.32  0.995797   \n",
       "5237978    0.999210   0.998970  125631.72   0.999210  669893.00  0.999008   \n",
       "5237979    1.001494   1.002129  250081.44   1.002447  300167.56  1.002274   \n",
       "\n",
       "           target  time_id       row_id  \n",
       "0       -3.029704        0        0_0_0  \n",
       "1       -5.519986        0        0_0_1  \n",
       "2       -8.389950        0        0_0_2  \n",
       "3       -4.010200        0        0_0_3  \n",
       "4       -7.349849        0        0_0_4  \n",
       "...           ...      ...          ...  \n",
       "5237975  2.310276    26454  480_540_195  \n",
       "5237976 -8.220077    26454  480_540_196  \n",
       "5237977  1.169443    26454  480_540_197  \n",
       "5237978 -1.540184    26454  480_540_198  \n",
       "5237979 -6.530285    26454  480_540_199  \n",
       "\n",
       "[5237980 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs_dir_path = pathlib.Path('../inputs')\n",
    "outputs_dir_path = pathlib.Path('../outputs')\n",
    "if not outputs_dir_path.is_dir():\n",
    "    outputs_dir_path.mkdir()\n",
    "\n",
    "train_df = pd.read_csv(inputs_dir_path. joinpath('train.csv'))\n",
    "display(train_df)\n",
    "train_df.drop(columns=['row_id', 'time_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_dtypes = {\n",
    "    'stock_id': np.int16,\n",
    "    'date_id': np.int16,\n",
    "    'seconds_in_bucket': np.int16,\n",
    "    'imbalance_size': np.float32,\n",
    "    'imbalance_buy_sell_flag': np.int16,\n",
    "    'reference_price': np.float32,\n",
    "    'matched_size': np.float32,\n",
    "    'far_price': np.float32,\n",
    "    'near_price': np.float32,\n",
    "    'bid_price': np.float32,\n",
    "    'bid_size': np.float32,\n",
    "    'ask_price': np.float32,\n",
    "    'ask_size': np.float32,\n",
    "    'wap': np.float32,\n",
    "    'target': np.float32\n",
    "}\n",
    "\n",
    "display(train_df.dtypes)\n",
    "train_df = train_df.astype(cast_dtypes)\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "])\n",
    "\n",
    "index_wap = (\n",
    "    train_df\n",
    "    .groupby(['date_id', 'seconds_in_bucket'])\n",
    "    .apply(lambda x: (weights[x['stock_id']] * x['wap']).sum() / weights[x['stock_id']].sum())\n",
    ")\n",
    "index_wap = pd.DataFrame(index_wap, columns=['index_wap'])\n",
    "train_df = train_df.merge(index_wap, on=['date_id', 'seconds_in_bucket'])\n",
    "display(train_df)\n",
    "\n",
    "del index_wap\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = pl.from_pandas(df)\n",
    "\n",
    "    new_features0 = [\n",
    "        (pl.col('imbalance_size') / 1e+06).name.keep(),\n",
    "        (pl.col('matched_size') / 1e+06).name.keep(),\n",
    "        (pl.col('bid_size') / 1e+06).name.keep(),\n",
    "        (pl.col('ask_size') / 1e+06).name.keep(),\n",
    "    ]\n",
    "    new_features1 = [\n",
    "        (pl.col('ask_price') - pl.col('bid_price')).alias('feature1'),\n",
    "        (pl.col('ask_price') - pl.col('reference_price')).alias('feature2'),\n",
    "        (pl.col('bid_price') - pl.col('reference_price')).alias('feature3'),\n",
    "        (pl.col('ask_price') - pl.col('wap')).alias('feature4'),\n",
    "        (pl.col('bid_price') - pl.col('wap')).alias('feature5'),\n",
    "        (pl.col('far_price') - pl.col('near_price')).alias('feature6'),\n",
    "        (pl.col('far_price') - pl.col('reference_price')).alias('feature7'),\n",
    "        (pl.col('near_price') - pl.col('reference_price')).alias('feature8'),\n",
    "        (pl.col('index_wap') - pl.col('reference_price')).alias('feature9'),\n",
    "        (pl.col('index_wap') - pl.col('ask_price')).alias('feature10'),\n",
    "        (pl.col('index_wap') - pl.col('bid_price')).alias('feature11'),\n",
    "        (pl.col('index_wap') - pl.col('far_price')).alias('feature12'),\n",
    "        (pl.col('index_wap') - pl.col('near_price')).alias('feature13'),\n",
    "        (pl.col('index_wap') - pl.col('wap')).alias('feature14'),\n",
    "        (pl.col('ask_size') - pl.col('bid_size')).alias('feature15'),\n",
    "        (pl.col('ask_size') - pl.col('matched_size')).alias('feature16'),\n",
    "        (pl.col('bid_size') - pl.col('matched_size')).alias('feature17'),\n",
    "        (pl.col('imbalance_size') - pl.col('matched_size')).alias('feature18'),\n",
    "        (pl.col('ask_price') + pl.col('bid_price')).alias('feature19'),\n",
    "        (pl.col('far_price') + pl.col('near_price')).alias('feature20'),\n",
    "        (pl.col('ask_size') + pl.col('bid_size')).alias('feature21'),\n",
    "        ((pl.col('ask_price') - pl.col('bid_price')) * ((pl.col('ask_size') - pl.col('bid_size')) / (pl.col('ask_size') + pl.col('bid_size')))).alias('feature22'),\n",
    "        ((pl.col('ask_price') - pl.col('reference_price')) * ((pl.col('ask_size') - pl.col('bid_size')) / (pl.col('ask_size') + pl.col('bid_size')))).alias('feature23'),\n",
    "        ((pl.col('bid_price') - pl.col('reference_price')) * ((pl.col('ask_size') - pl.col('bid_size')) / (pl.col('ask_size') + pl.col('bid_size')))).alias('feature24'),\n",
    "        ((pl.col('ask_price') - pl.col('wap')) * ((pl.col('ask_size') - pl.col('bid_size')) / (pl.col('ask_size') + pl.col('bid_size')))).alias('feature25'),\n",
    "        ((pl.col('bid_price') - pl.col('wap')) * ((pl.col('ask_size') - pl.col('bid_size')) / (pl.col('ask_size') + pl.col('bid_size')))).alias('feature26'),\n",
    "        ((pl.col('ask_price') - pl.col('bid_price')) * ((pl.col('matched_size') - pl.col('imbalance_size')) / (pl.col('matched_size') + pl.col('imbalance_size')))).alias('feature27'),\n",
    "        ((pl.col('ask_price') - pl.col('reference_price')) * ((pl.col('matched_size') - pl.col('imbalance_size')) / (pl.col('matched_size') + pl.col('imbalance_size')))).alias('feature28'),\n",
    "        ((pl.col('bid_price') - pl.col('reference_price')) * ((pl.col('matched_size') - pl.col('imbalance_size')) / (pl.col('matched_size') + pl.col('imbalance_size')))).alias('feature29'),\n",
    "        ((pl.col('ask_price') - pl.col('wap')) * ((pl.col('matched_size') - pl.col('imbalance_size')) / (pl.col('matched_size') + pl.col('imbalance_size')))).alias('feature30'),\n",
    "        ((pl.col('bid_price') - pl.col('wap')) * ((pl.col('matched_size') - pl.col('imbalance_size')) / (pl.col('matched_size') + pl.col('imbalance_size')))).alias('feature31'),\n",
    "\n",
    "        (pl.col('bid_price') / pl.col('ask_price')).alias('feature32'),\n",
    "        (pl.col('reference_price') / pl.col('ask_price')).alias('feature33'),\n",
    "        (pl.col('reference_price') / pl.col('bid_price')).alias('feature34'),\n",
    "        (pl.col('wap') / pl.col('ask_price')).alias('feature35'),\n",
    "        (pl.col('wap') / pl.col('bid_price')).alias('feature36'),\n",
    "        (pl.col('index_wap') / pl.col('ask_price')).alias('feature37'),\n",
    "        (pl.col('index_wap') / pl.col('bid_price')).alias('feature38'),\n",
    "        (pl.col('index_wap') / pl.col('reference_price')).alias('feature39'),\n",
    "        (pl.col('index_wap') / pl.col('wap')).alias('feature40'),\n",
    "\n",
    "        (pl.col('bid_size') / pl.col('ask_size')).alias('feature41'),\n",
    "        (pl.col('ask_size') / pl.col('matched_size')).alias('feature42'),\n",
    "        (pl.col('bid_size') / pl.col('matched_size')).alias('feature43'),\n",
    "        (pl.col('bid_size') / pl.col('imbalance_size')).alias('feature44'),\n",
    "        (pl.col('ask_size') / pl.col('imbalance_size')).alias('feature45'),\n",
    "        (pl.col('matched_size') / pl.col('imbalance_size')).alias('feature46'),\n",
    "    ]\n",
    "\n",
    "    base_features = [\n",
    "        'imbalance_size',\n",
    "        'imbalance_buy_sell_flag',\n",
    "        'matched_size',\n",
    "        'reference_price',\n",
    "        'far_price',\n",
    "        'near_price',\n",
    "        'bid_size',\n",
    "        'bid_price',\n",
    "        'ask_size',\n",
    "        'ask_price',\n",
    "        'wap',\n",
    "        'index_wap',\n",
    "    ]\n",
    "    #base_features += [f'feature{i}' for i in range(1, 47)]\n",
    "    \n",
    "    new_features2 = [\n",
    "        pl.col(base_features).sort_by(['date_id', 'seconds_in_bucket']).pct_change(n=1).over(['stock_id']).name.prefix('pct_change1_'),\n",
    "        pl.col(base_features).sort_by(['date_id', 'seconds_in_bucket']).pct_change(n=6).over(['stock_id']).name.prefix('pct_change6_'),\n",
    "        pl.col(base_features).sort_by(['date_id', 'seconds_in_bucket']).pct_change(n=12).over(['stock_id']).name.prefix('pct_change12_'),\n",
    "    ]\n",
    "\n",
    "    new_features3 = [\n",
    "        ((pl.col(feature) - pl.col(feature).mean()) / pl.col(feature).std())\n",
    "        .over(['date_id', 'seconds_in_bucket'])\n",
    "        .alias(f'standardized_{feature}')\n",
    "        for feature in base_features\n",
    "    ]\n",
    "\n",
    "    replace_inf = [\n",
    "        pl.when(pl.col(feature).is_infinite()).then(None).otherwise(pl.col(feature)).name.keep()\n",
    "        for feature in df.columns\n",
    "    ]\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .with_columns(new_features0)\n",
    "        .with_columns(new_features1)\n",
    "        .with_columns(new_features2)\n",
    "        .with_columns(new_features3)\n",
    "        .with_columns(replace_inf)\n",
    "        .drop(['row_id'])\n",
    "        .sort(by=['stock_id', 'date_id', 'seconds_in_bucket'])\n",
    "        .to_pandas()\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess(train_df)\n",
    "train_df = train_df.dropna(subset=['target'])\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train lightgbm models using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        df: pd.DataFrame,\n",
    "        model_params: Dict[str, Any],\n",
    "        outputs_dir: pathlib.Path,\n",
    "        step: int,\n",
    "    ):\n",
    "    \n",
    "    target_columns = ['stock_id', 'date_id', 'seconds_in_bucket', 'target']\n",
    "    feature_columns = [col for col in df.columns if col not in ['date_id', 'target', 'cluster']]\n",
    "    fimps = []\n",
    "    history = {\n",
    "        'train_mae': [],\n",
    "        'valid_mae': [],\n",
    "    }\n",
    "    oofs = []\n",
    "\n",
    "    df = df.sort_values(by=['cluster', 'stock_id', 'date_id', 'seconds_in_bucket'])\n",
    "    groups = df['cluster']\n",
    "\n",
    "    cv_args = {'n_splits': 5, 'test_size': 1}\n",
    "    kfold = GroupTimeSeriesSplit(**cv_args)\n",
    "\n",
    "    plot_splits(df, y=None, groups=groups, **cv_args)\n",
    "\n",
    "    for k, (train_indices, valid_indices) in enumerate(kfold.split(X=df, groups=groups)):\n",
    "\n",
    "        train_X = df.iloc[train_indices][feature_columns]\n",
    "        train_y = df.iloc[train_indices][target_columns]\n",
    "        valid_X = df.iloc[valid_indices][feature_columns]\n",
    "        valid_y = df.iloc[valid_indices][target_columns]\n",
    "        print(f'train_X.shape: {train_X.shape}, train_y.shape: {train_y.shape}')\n",
    "        print(f'valid_X.shape: {valid_X.shape}, valid_y.shape: {valid_y.shape}')\n",
    "\n",
    "        callbacks = [\n",
    "            lgb.early_stopping(stopping_rounds=100, verbose=True),\n",
    "            lgb.log_evaluation(500),\n",
    "        ]\n",
    "        \n",
    "        train_dataset = lgb.Dataset(\n",
    "            train_X,\n",
    "            train_y['target'],\n",
    "            #categorical_feature=['imbalance_buy_sell_flag'],\n",
    "        )\n",
    "\n",
    "        valid_dataset = lgb.Dataset(\n",
    "            valid_X,\n",
    "            valid_y['target'],\n",
    "            #categorical_feature=['imbalance_buy_sell_flag'],\n",
    "        )\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params=model_params,\n",
    "            train_set=train_dataset,\n",
    "            valid_sets=[train_dataset, valid_dataset],\n",
    "            valid_names=['train', 'valid'],\n",
    "            callbacks=callbacks,\n",
    "            num_boost_round=5000,\n",
    "        )\n",
    "        model.save_model(\n",
    "            outputs_dir.joinpath(f'lightgbm_fold{k+1}.txt'),\n",
    "            num_iteration=model.best_iteration\n",
    "        )\n",
    "        \n",
    "        fimp = model.feature_importance(importance_type='gain')\n",
    "        fimp = pd.DataFrame(fimp, index=feature_columns, columns=[f'fold{k+1}'])\n",
    "        fimps.append(fimp)\n",
    "\n",
    "        train_pred = model.predict(train_X, num_iteration=model.best_iteration)\n",
    "        valid_pred = model.predict(valid_X, num_iteration=model.best_iteration)\n",
    "\n",
    "        history['train_mae'].append(mean_absolute_error(train_y['target'], train_pred))\n",
    "        history['valid_mae'].append(mean_absolute_error(valid_y['target'], valid_pred))\n",
    "\n",
    "        valid_y['regression'] = valid_pred\n",
    "        oofs.append(valid_y)\n",
    "        \n",
    "        del train_X, train_y, train_dataset, valid_X, valid_y, valid_dataset, model, fimp\n",
    "        del train_pred, valid_pred\n",
    "        gc.collect()\n",
    "\n",
    "    history = pd.DataFrame.from_dict(history)\n",
    "    \n",
    "    fimps = pd.concat(fimps, axis=1)\n",
    "    mean_fimps = fimps.mean(axis=1)\n",
    "    std_fimps = fimps.std(axis=1)\n",
    "    fimps['mean_fimps'] = mean_fimps\n",
    "    fimps['std_fimps'] = std_fimps\n",
    "    fimps.sort_values(by='mean_fimps', inplace=True)\n",
    "\n",
    "    oofs = pd.concat(oofs)\n",
    "    oof_mae = mean_absolute_error(oofs['target'], oofs['regression'])\n",
    "    \n",
    "    print(f'test_y mae: {oof_mae:.4f}')\n",
    "    \n",
    "    with open(outputs_dir.joinpath('oofs_lightgbm_optuna.yaml'), 'w') as f:\n",
    "        yaml.dump(\n",
    "            {\n",
    "                'oof_mae': oof_mae,\n",
    "            },\n",
    "            f,\n",
    "            default_flow_style=False\n",
    "        )\n",
    "    return history, oofs, fimps\n",
    "\n",
    "\n",
    "def plot_time(all_time, train_time, valid_time):\n",
    "    _, ax = plt.subplots()\n",
    "    ax.barh(y='all', height=0.6, width=len(all_time), left=0, color='tab:blue')\n",
    "    ax.barh(y='train+valid+test', height=0.6, width=[len(train_time), len(valid_time)],\n",
    "            left=[train_time.min(), valid_time.min()], color=['tab:orange', 'tab:green', 'tab:red'])\n",
    "    xcenter = [len(all_time)//2, train_time.min()+len(train_time)//2,\n",
    "               valid_time.min()+len(valid_time)//2]\n",
    "    ycenter = [0, 1, 1, 1]\n",
    "    width = [f'all\\n{len(all_time)}', f'train\\n{len(train_time)}', f'valid\\n{len(valid_time)}']\n",
    "    for x, y, w in zip(xcenter, ycenter, width):\n",
    "        ax.text(x, y, str(w),  ha='center', va='center')\n",
    "    ax.set_xticks([train_time.min(), valid_time.min(), valid_time.max(), len(all_time)])\n",
    "    ax.grid(axis='x', linestyle='--')\n",
    "    ax.tick_params(axis='x', labelrotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'mae',\n",
    "    'metric': 'mae',\n",
    "    'learning_rate': 1e-02,\n",
    "    'seed': 42,\n",
    "    'max_depth':  10,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'feature_fraction': 1.0,\n",
    "    'feature_fraction_bynode': 0.6,\n",
    "    'lambda_l2': 0.0,\n",
    "    #'bagging_fraction': 0.6,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "history, oofs, fimps = train(\n",
    "    df=train_df,\n",
    "    model_params=params,\n",
    "    outputs_dir=outputs_dir_path,\n",
    "    step=120,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(oofs)\n",
    "print(fimps.shape)\n",
    "display(fimps.tail(50))\n",
    "\n",
    "_, ax = plt.subplots(figsize=(12, 24))\n",
    "fimps['mean_fimps'].plot(kind='barh', xerr=fimps['std_fimps'], capsize=3, ax=ax)  \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fimps_quantile_th = fimps['mean_fimps'].quantile(q=0.2)\n",
    "display(fimps.query('mean_fimps < @fimps_quantile_th').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.plot(marker='.', linestyle=':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "ax.hist2d(oofs['regression'], oofs['target'], bins=100, cmap='Blues', vmax=1e+03)\n",
    "ax.plot([-100, 100], [-100, 100], color='tab:orange')\n",
    "ax.set_xlabel('regression')\n",
    "ax.set_ylabel('target')\n",
    "plt.show()\n",
    "\n",
    "r = np.corrcoef(oofs['regression'], oofs['target'])\n",
    "print(f'correlation coeeficient: {r[0, 1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_per_sotck = oofs.groupby('stock_id')[['target', 'regression']].apply(lambda x: np.mean(abs(x['target'] - x['regression'])))\n",
    "display(mae_per_sotck.describe())\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(mae_per_sotck.values, marker='o', linestyle=':')\n",
    "plt.show()\n",
    "\n",
    "display(mae_per_sotck[mae_per_sotck <= 6])\n",
    "display(mae_per_sotck[mae_per_sotck <= 6].describe())\n",
    "\n",
    "display(mae_per_sotck[mae_per_sotck > 6])\n",
    "display(mae_per_sotck[mae_per_sotck > 6].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 1, sharex=True)\n",
    "bins = np.linspace(-100, 100, 100)\n",
    "axs[0].hist(oofs.query('stock_id in @mae_per_sotck[@mae_per_sotck <= 6].index')['target'], bins=bins, histtype='step', density=True)\n",
    "axs[0].hist(oofs.query('stock_id in @mae_per_sotck[@mae_per_sotck > 6].index')['target'], bins=bins, histtype='step', density=True)\n",
    "axs[1].hist(oofs.query('stock_id in @mae_per_sotck[@mae_per_sotck <= 6].index')['regression'], bins=bins, histtype='step', density=True)\n",
    "axs[1].hist(oofs.query('stock_id in @mae_per_sotck[@mae_per_sotck > 6].index')['regression'], bins=bins, histtype='step', density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 0\n",
    "\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=oofs.query('stock_id==@stock').index, y=oofs.query('stock_id==@stock')['target'],\n",
    "        name='target', mode='lines+markers', marker={'size': 5},\n",
    "    ),\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=oofs.query('stock_id==@stock').index, y=oofs.query('stock_id==@stock')['regression'],\n",
    "        name='target', mode='lines+markers', marker={'size': 5},\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 31\n",
    "\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=oofs.query('stock_id==@stock').index, y=oofs.query('stock_id==@stock')['target'],\n",
    "        name='target', mode='lines+markers', marker={'size': 5},\n",
    "    ),\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=oofs.query('stock_id==@stock').index, y=oofs.query('stock_id==@stock')['regression'],\n",
    "        name='target', mode='lines+markers', marker={'size': 5},\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train lightgbm model using all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_columns = ['stock_id', 'date_id', 'seconds_in_bucket', 'target']\n",
    "# feature_columns = [col for col in train_df.columns if col not in ['date_id', 'target']]\n",
    "\n",
    "# callbacks = [\n",
    "#     lgb.log_evaluation(500),\n",
    "# ]\n",
    "\n",
    "# train_dataset = lgb.Dataset(\n",
    "#     train_df[feature_columns],\n",
    "#     train_df[target_columns]['target'],\n",
    "# )\n",
    "\n",
    "# del train_df\n",
    "# gc.collect()\n",
    "\n",
    "# model = lgb.train(\n",
    "#     params=params,\n",
    "#     train_set=train_dataset,\n",
    "#     callbacks=callbacks,\n",
    "#     num_boost_round=5000,\n",
    "# )\n",
    "\n",
    "# model.save_model(\n",
    "#     outputs_dir_path.joinpath(f'lightgbm_trained_using_alldata.txt'),\n",
    "#     num_iteration=model.best_iteration,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
